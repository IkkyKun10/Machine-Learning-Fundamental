# -*- coding: utf-8 -*-
"""Submission 3 - Deployment Clasification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p3xau6Udk-5Yq_LhmaZQU6P8KQ4GKvI0
"""

import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator

from keras.layers import Input
import numpy as np
import matplotlib.pyplot as plt
import pathlib

import os
import shutil
import zipfile

from tensorflow import feature_column
from keras import layers
from sklearn.model_selection import train_test_split

zip_data = "/content/flower-recognition.zip"
zip_ref = zipfile.ZipFile(zip_data, "r")
zip_ref.extractall('/content')
zip_ref.close()

dataset_dir = os.path.join("flowers")
labels = os.listdir(dataset_dir)

labels

labels_and_items = {}

for label in labels:
  items = os.listdir(os.path.join(dataset_dir, label))
  labels_and_items[label] = len(items)

labels_and_items

def delete_label(label):
  shutil.rmtree(os.path.join(dataset_dir, label))
  labels.remove(label)
  labels_and_items.pop(label)

delete_label('dandelion')
delete_label('tulip')

labels_and_items

datagen = ImageDataGenerator(
    rescale=1./255.0,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    zoom_range=0.2,
    fill_mode='nearest',
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)
    
validation_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

input_shape = (150, 150, 3)

model = tf.keras.models.Sequential([
                                    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
                                    layers.MaxPooling2D(2, 2),
                                    layers.Conv2D(64, (3, 3), activation='relu'),
                                    layers.MaxPooling2D(2, 2),                                  
                                    layers.Conv2D(128, (3, 3), activation='relu'),
                                    layers.MaxPooling2D(2, 2),
                                    layers.Flatten(),
                                    layers.Dropout(0.2),
                                    layers.Dense(256, activation='relu'),
                                    layers.Dense(3, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

class MyCallback(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if logs.get("accuracy") >= 0.8500 and logs.get("val_accuracy") >= 0.8500:
      print("Accuracy & Val accuracy was over 85%. Stop training...")
      self.model.stop_training = True

callbacks = MyCallback()

hist = model.fit(
    train_generator,
    epochs=50,
    validation_data=validation_generator,
    callbacks=[callbacks]
)

plt.plot(hist.history["accuracy"])
plt.plot(hist.history["val_accuracy"])
plt.title("Akurasi Model")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train", "test"], loc="upper left")
plt.show()

plt.plot(hist.history["loss"])
plt.plot(hist.history["val_loss"])
plt.title("Loss Model")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(["train", "test"], loc="upper left")
plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile("model.tflite", "wb") as f:
  f.write(tflite_model)